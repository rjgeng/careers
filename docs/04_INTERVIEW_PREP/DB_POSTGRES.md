# DB Interview Cheat Card ‚Äî FAANG / Staff‚ÄëLevel Framing (Postgres‚ÄëFirst)

## Executive Framing (how Staff engineers start)

**Postgres is the default system of record (SoR).**
The primary goal is **risk reduction and long‚Äëterm operability**, not premature scale.
We scale by **exhausting simplicity** before introducing irreversible complexity.

---

## Staff‚ÄëLevel Mental Model

* **System of Record (Postgres)**

  * invariants, constraints, transactions, migrations
  * correctness > performance
* **Acceleration Layer (add only when measured)**

  * Redis ‚Üí latency, rate‚Äëlimiting, coordination
  * pgvector / vector DB ‚Üí semantic retrieval
  * Search engine ‚Üí advanced text search
* **Distribution Layer (last resort)**

  * Vitess / PlanetScale ‚Üí horizontal write sharding

> Staff signal: *each layer increases blast radius and operational surface area.*

---

## System‚ÄëDesign Decision Tree (FAANG‚Äëstyle whiteboard)

```text
Start: correctness + operability
  |
  v
Need transactions / constraints?
  ‚Üí Yes ‚Üí Postgres (SoR)
        |
        |-- Read bottleneck?
        |      ‚Üí replicas / Redis cache
        |
        |-- Write bottleneck?
        |      ‚Üí schema/indexing ‚Üí vertical scale ‚Üí replicas
        |
        |-- AI / semantic access?
        |      ‚Üí pgvector ‚Üí external vector DB (if scale demands)
        |
        |-- Sustained write hotspots?
               ‚Üí consider sharding (Vitess / PlanetScale)
```

---

## üîî Readiness Signals for Vitess / PlanetScale (Staff bar)

Sharding is justified **only if all are true**:

* Sustained **high write QPS** (steady‚Äëstate, not spikes)
* **Hot shard keys** are inherent to the domain (tenant/org/user)
* Top tenants dominate load and cannot be isolated with replicas
* Vertical scaling ceiling reached (CPU, IO, lock contention)
* Team owns **resharding, schema coordination, and cross‚Äëshard limits**

> Staff heuristic: *If sharding is optional, it is premature.*

---

## üö® Common False Positives (explicitly call these out)

* ‚ÄúHigh traffic‚Äù (reads ‚â† writes)
* Slow queries (indexing / plans first)
* Large datasets (size ‚â† contention)
* Viral‚Äëgrowth fear
* Multi‚Äëtenancy without hotspots
* ORM overhead masking schema issues

Sharding solves **write‚Äëcontention physics**, not general performance anxiety.

---

## 45‚ÄëSecond FAANG Interview Answer

> ‚ÄúWe anchor on Postgres as the system of record to preserve correctness and operability. We scale vertically, then add read replicas and Redis for latency and coordination. For AI features, we start with pgvector and externalize only if retrieval scale demands it. We treat sharding via Vitess or PlanetScale as a last‚Äëresort decision, justified only by sustained write hotspots and organizational readiness, because it permanently increases system complexity.‚Äù

---

## Staff‚ÄëLevel Resume Bullets

* Led **Postgres‚Äëfirst** data architecture as system of record, prioritizing correctness and operability
* Scaled production systems via **vertical growth, replicas, and Redis** before introducing sharding
* Integrated **vector search** while preserving transactional integrity
* Evaluated and deferred **Vitess/PlanetScale** adoption until write‚Äëhotspot pressure justified complexity

---

## Whiteboard Closing Line (strong signal)

> ‚ÄúWe treat distributed databases as an organizational decision, not just a technical one.‚Äù


## Next 


Ask ChatGPT

-   Tailor this **per FAANG company** (Google vs Meta vs Amazon vs Apple)
-   Convert it into a **spoken 60-second script** you can rehearse
-   Or map it directly to a **real system prompt** (e.g., chat app, ads system, AI product)
